chapter 05

# 통계적 추론
- 고려 중인 모집단으로부터 추출한 표본을 기초로 모집단이나 모수를 추정하고 검정
- 모수(parameter) : 모집단의 특성을 나타내는 것
- 통계량(statistic) : 표본의 특성을 나타내는 것
- 추정(estimation) : 모수의 참값으로 추측되는 값을 구하는 과정
- 점추정(point estimation) : 모수의 참값이라고 추측되는 하나의 값을 구하는 것
- 구간추청(interval estimation) : 모수의 참값을 포함할 것이라고 추측되는 구간을 구하는 것
- 가설검정(hypothesis testing) : 모수에 대한 추정의 옳고 그름을 판단하는 과정
- 추정 방법
    고전적 방법(classical method) : 확률표본에 기반하여 모수를 추정
    베이지안 방법(bayesian method) : 표본 정보와 함께 모수의 사전 확률분포를 이용
- 추정값 : 실제 표본 데이터를 적용해 얻은 수치 결과
- 추정량 : 표본 통계량을 이용해 모수를 추측하는 계산식(아래 표의 원소를 모두 포함)
      구분       평균  분산  표준편차  비율  상관계수
    모집단 (θ)    μ    σ²    σ      p     ρ      (모수)
    통계량 (Θ̂)    X̄    S²    S      p̂     p̂      (추정량, 세타 대문자 써야 함)
    추정값 (Θ̂)    x̄    s²    s      p̂     p̂
- 표준오차(standard error, SE) : 추정했을 때, 실제 값하고 얼마나 차이가 나는지.
- 추정량 정의 :
    μ(X1,X2,···,Xn) = X -> 모평균μ을 추정하기 위한 도구(함수)를 X̄(표본평균)라고 부른다
    σ²(X1,X2,···,Xn) = S² -> 모분산σ²을 추정하기 위한 도구를 S²(표본분산)라고 부른다

# 점추정(point estimation)
- 정의 : 모수의 참값이라고 추측되는 하나의 값을 구하는 것
- 좋은 추정량에 대한 판단 기준
    불편성(unbiascedness) : 추정량의 기대값이 모수를 정확히 반영
    -> 추정량의 기댓값이 모수를 반영해야 함
    최소분산성(efficiency) : 추정량의 분산이 작을수록 더 정확한 추정
    -> 분산이 작을수록 더 정확함
    일치성(consistency) : 표본 크기가 커질수록 추정량이 모수에 수렴
    -> 표본 크기가 커질수록 추정량이 모수에 수렴해야 함
- 편의(bias) : 어떤 모수 θ의 추정량을 Θ̂라고 할 때,
    -> Bias(Θ̂) = E[Θ̂] − θ
- 불편추정량(unbiased estimator) : 편의가 0이면 Θ̂는 불편성을 가짐.
    -> 이 때 Θ̂를 θ의 불편추정량이라고 함

ex) 5.3
- N(μ, σ²)를 따르는 정규모집단에서 추출한 확률표본 X₁, X₂, X₃에 대해 μ̂₁ = 1/3(X₁ + X₂ + X₃)가 μ의 불편추정량임을 보여라
-> sol) 불편추정량이 되려면, 추정량의 기댓값(E)이 추정하려는 모수(μ)와 같아야 함
        X₁, X₂, X₃는 모두 정규분포를 따름. 따라서 각각의 기댓값은 μ
        ∴ E[μ̂₁] = μ

ex) 5.4
- B(1. p)를 따르는 모집단에서 추출한 확률표본 X₁, X₂, ..., Xₙ에 대해 표본비율 p̂ = (∑Xᵢ)/n이 모비율 p의 불편추정량임을 보여라
-> sol) 베르누이 분포의 정의에 의해 E[Xᵢ] = p이다. 
        따라서 E[(∑Xᵢ)/n] = (n * p) / n = p
        ∴ E[p̂] = p

ex) 5.5
- N(μ, σ²)를 따르는 정규모집단에서 추출한 확률표본 X₁, X₂, ..., Xₙ의 표본분산 S²가 모분산 σ²의 불편추정량임을 보여라
-> sol) (n - 1) * S² / σ²는 χ²(n - 1)을 따름. X ~ χ²(v)일 때, E[X] = v. 위의 통계랑은 카이제곱분포의 정의에 따라 카이제곱분포를 따름
        확률변수 Y = X₁, X₂, ..., Xₙ
        E[Y] = (n - 1)/σ² * E[S²] = n - 1 
        ∴ E[S²] = σ²

ex) 5.6
- 일반 모집단에서 추출한 확률표본 X₁, X₂, ..., Xₙ에 대해 표본분산 S²가 모분산 σ²의 불편추정량임을 보여라
-> sol) goal : E[S²] = σ²임을 보이기
        S² = ∑(i = i ~ n) (X̄ - Xᵢ)² * (1/(n-1))
        ∑(i = i ~ n) (X̄ - Xᵢ)² 
            = ∑(i = i ~ n)((X̄ - μ) - (Xᵢ - μ))²
            = ∑(i = i ~ n) ((X̄ - μ)² - 2*(X̄ - μ)*(Xᵢ - μ) + (Xᵢ - μ)²)
            = n*(X̄ - μ)² - 2*(X̄ - μ)*∑(Xᵢ - μ) + ∑(Xᵢ - μ)²
            = n*(X̄ - μ)² - 2*(X̄ - μ)*n*(X̄ - μ) + ∑(Xᵢ - μ)²
            = n*(X̄ - μ)² - 2*n*(X̄ - μ)² + ∑(Xᵢ - μ)²
            = ∑(Xᵢ - μ)² - n*(X̄ - μ)²
        E[∑(X̄ - Xᵢ)²] 
            = ∑E[(Xᵢ - μ)²] - n*E[(X̄ - μ)²]
            = ∑σ² - n(σ²/n)
            = nσ² - σ²
            = (n - 1)σ²
        E[∑(X̄ - Xᵢ)²] * (1/(n-1)) = σ²
        ∴ E[S²] = σ²
        
- 불편추정량에 대한 생각 : 
    추정량이 불편추정량이면 가장 바람직한 추정량인가?
    -> 아님. 분산(산포 정도)가 매우 크다면 큰 오차 발생 가능
- 평균제곱오차(mean square error, MSE) : 모수 θ에 대한 추정량 Θ̂의 평균제곱오차
    -> MSE(Θ̂) = E[(Θ̂ - θ)²]
              = Var(Θ̂) + (Bias(Θ̂))²
    -> 불편추정량이 아닐 경우, 점추정량을 결정하는 기준으로 사용하기도 함
- 최소분산불편추정치(minimum variance unbiased estimator, MVUE) : 불편성을 만족하면서 최소의 분산을 가지는 값
    두 불편추정량 Θ̂₁, Θ̂₂에 대해
    1. Var(Θ̂₁) < Var(Θ̂₂)이면 Θ̂₁가 Θ̂₂보다 유효
    2. Θ̂₁에 대한 Θ̂₂의상대효율 : Var(Θ̂₁)/Var(Θ̂₂) 
- 일치추정량(consistent estimator) : 모수 θ의 표본 n개를 이용한 추정량 Θ̂ₙ = Θ̂(X₁, X₂, ..., Xₙ)이 임의의 ε > 0에 대해 다음을 만족
    lim(n -> ∞) P(|Θ̂ - θ| < ε) = 1  
    or lim(n -> ∞) P(|Θ̂ - θ| >= ε) = 0

    또는 lim(n -> ∞) E[Θ̂ₙ] = θ과 lim(n -> ∞) Var(Θ̂ₙ) = 0을 만족 (평균제곱오차가 0으로 수렴)

ex) 5.8
- 평균이 μ, 분산이 σ²인 모집단에서 추출한 확률표본 X₁, X₂, ..., Xₙ에 대해 표본평균 X̄가 μ의 일치추정량이고 표본분산 S²이 σ²의 일치추청량임을 보여라
-> sol) 1. X̄의 불편성과 최소분산성을 보일 것임
        Step 1 : 기댓값 확인. 표본평균의 기댓값은 모평균과 같음
            -> E[X̄] = μ
        ∴ X̄는 불편추정량
        Step 2 : 분산이 무한으로 갈 때의 값이 0인지 확인(최소분산 확인)
            -> lim(n -> ∞) Var(X̄) = lim σ² / n = 0
        ∴ X̄의 최소 분산은 0
        ∴ X̄는 μ의 일치추정량

        2. S²의 불편성과 최소분산성
        Step 1 : 기댓값
            -> E[S²] = σ² (위에서 증명)
        ∴ S²는 불편추정량
        Step 2 : 분산의 분산이 무한으로 갈 때 0인지 확인
            -> 어떤 통계량의 분산은 Var(임의의 다른 통계량) / n로 정의될 수 있음
            S² = ∑(i = i ~ n) (X̄ - Xᵢ)² * (1/(n-1))
                여기에서, (X̄ - Xᵢ)² = Zᵢ라고 정의.
               = (1/(n-1)) * ∑Zᵢ
            lim(n -> ∞) Var(S²) = lim Var((1/(n-1)) * ∑Zᵢ)
                여기에서, n이 무한으로 가기 때문에 (1/(n-1)) * ∑Zᵢ는 Z̄로 근사할 수 있엄
            = lim Var(Z̄) = lim Var(Z) / n = 0
        ∴ S²의 최소 분산은 0
        ∴ S²는 σ²의 일치추정량

# 적률추정법(method of moments​​)
- 적률(moment) : 확률변수 X의 r차 적률이라고 함
    -> μᵣ = E[Xʳ]
- 중심적률(central moment) 
    -> μᵣᶜ = E[(X - μ)ʳ]
- 주요 적률과 의미
    1차 적률 : μ₁ = E[X] -> 평균
    2차 중심적률 : μ₂ᶜ = E[(X - μ)²] -> 분산
    3차 중심적률 : 왜도, 4차 중심적률 : 첨도
- 표본적률(sample moment) 
    -> μ̂̂ᵣ = (1/n) * ∑(i = 1 ~ n)Xᵢʳ
- 모적률(population moment)
    -> μᵢ = E[Xⁱ]
- 적률추정량(method of moments​​ estimator) : 모수를 이루는 적률들에 대응하는 표본적률의 결합으로 표현되는 추정량 Θ̂
    추정하는 모수 θ가 모적률 μ₁, μ₂, ..., μₙ의 결합으로 표현될 때,
    -> θ = h(μ₁, μ₂, ..., μₙ)일 때,
    모수 θ의 표본 n개를 이용한 추정량 Θ̂ₙ = Θ̂(X₁, X₂, ..., Xₙ)이 아래 통계량에 의해 추정되면 Θ̂를 적률추정량이라고 함
    -> Θ̂(X₁, X₂, ..., Xₙ) = h(μ̂₁, μ̂₂, ..., μ̂ₙ)

ex) 5.9
- 확률표본 X₁, X₂, ..., Xₙ을 모집단 X ~ B(m, p)에서 추출하였을 때, θ₁ = mp와 θ₂ = mp(1 - p)의 적률추정량을 구해라
-> sol) 1. mp는 이항분포의 평균(1차 적률).
        μ̂₁ = X̄ 
        ∴ θ̂₁ = X̄ = (1/n) * ∑(i = 1 ~ n) Xᵢ

        2. mp(1 - p)는 이항분포의 분산(2차 적률 - 1차 적률의 제곱)
        μ₂ - μ₁² = mp - mp²
        ∴ θ̂₂ = mp̂(1 - p̂) = X̄(1 - X̄/m)

- 우도함수(likehood function) : 모집단이 미지의 모수 θ에 의존하는 f(x; θ)를 따르고, 확률표본 X₁, X₂, ..., Xₙ으로부터 구성된 관측값 x₁, x₂, ..., xₙ에 대해
    L(θ; x₁, x₂, ..., xₙ) = fX₁, X₂, ..., Xₙ(x₁, x₂, ..., xₙ; θ)
    과 같은 결합확률밀도함수 L(θ).
- 최대가능도 추정법(maximum likehood estimate, MLE) : 우도함수 L(θ)를 최대로 하는 θ값에 대한 추정치 θ̂를 구하는 것
    using : 1. 관심있는 모수에 대한 정보 부족할 떄
            2. 모집단의 추종 확률분포는 알지만, 구체적인 모수값은 모를 때
            3. 합리적인 추정량을 선택하기 어려울 때
    prop : 1. 우도함수가 미분가능히면 이를 최대로 하는 θ는 L'(θ) = 0을 만족 (당연?)
           2. 확률표본들이 서로 독립이며 같은 분포를 가진다면 L(θ) = Π(k = 1 ~ n) f(xₖ; θ)를 만족

ex) 5.11
- X₁, X₂, ..., Xₙ을 X ~ Pois(θ)로부터 추출한 표본이라고 할 때, θ에 대한 최대가능도 추정량은?
-> sol) 1. f(x;θ)(pdf) : e⁻ᶿ * θˣ/x!
        2. 위의 확률변수들은 독립. 따라서 우도함수는 확률밀도함수의 곱으로 표현된다.
        ∴ L(θ) = Π(k = 1 ~ n) e⁻ᶿ * θ^xₖ/xₖ!
               = e⁻ⁿᶿ(∑θ^xₖ) / Πxₖ!
        3. 미분계수가 0인 곳을 찾아야 하는데, 미분하기 어려우니 ln을 취함
        ln L(θ) = l(θ) = (-nθ) + lnθ * ∑xₖ + ∑ln(xₖ!)
        l'(θ) = -n + (1/θ)∑xₖ 
        4. 여기에서, 미분계수 = 0 계산하여 θ 추출
        ∴ polar point of θ = (1/n)∑xₖ
        그런데, 여기에서 (1/n)∑xₖ. 이는 평균(X̄)임을 익히 알고 있음
        ∴ MLE θ̂ = X̄

# 구간추정(interval estimation)
- 정의 : 모수의 참값을 포함할 것이라고 추측되는 구간을 구하는 것
- 신뢰구간(confidence interval) : 모수를 값이 아니고 고려된 구간으로 나타낸 것 
- 오차한계(error bound) : 두 구간의 차의 절댓값의 반 (|b - a| / 2)
- 모평균의 신뢰구간 추청 방법:
    case A. σ²를 알 때
        1. 정규모집단인 경우 -> Z 통계량 사용
        2. 비정규모집단이며 n >= 30인 경우 -> Z 통계량으로 근사
    case B. σ²를 모를 때(s²으로 대신 사용)
        1. 정규 -> t 통계량 사용
        2. 비정규, 30 -> Z 통계량으로 근사
- note. σ²이 알려진 모집단에서 모평균 μ의 100(1 - a)%의 신뢰구간
    x̄ - z_a/2 * σ / √n < μ < x̄ + z_a/2 * σ / √n
    -> 걍 파이썬 코드 Z.pdf of Z.ppf 하면 됨
    










  
