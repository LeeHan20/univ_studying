chapter 05

# 통계적 추론
- 고려 중인 모집단으로부터 추출한 표본을 기초로 모집단이나 모수를 추정하고 검정
- 모수(parameter) : 모집단의 특성을 나타내는 것
- 통계량(statistic) : 표본의 특성을 나타내는 것
- 추정(estimation) : 모수의 참값으로 추측되는 값을 구하는 과정
- 점추정(point estimation) : 모수의 참값이라고 추측되는 하나의 값을 구하는 것
- 구간추청(interval estimation) : 모수의 참값을 포함할 것이라고 추측되는 구간을 구하는 것
- 가설검정(hypothesis testing) : 모수에 대한 추정의 옳고 그름을 판단하는 과정
- 추정 방법
    고전적 방법(classical method) : 확률표본에 기반하여 모수를 추정
    베이지안 방법(bayesian method) : 표본 정보와 함께 모수의 사전 확률분포를 이용
- 추정값 : 실제 표본 데이터를 적용해 얻은 수치 결과
- 추정량 : 표본 통계량을 이용해 모수를 추측하는 계산식(아래 표의 원소를 모두 포함)
      구분       평균  분산  표준편차  비율  상관계수
    모집단 (θ)    μ    σ²    σ      p     ρ      (모수)
    통계량 (Θ̂)    X̄    S²    S      p̂     p̂      (추정량, 세타 대문자 써야 함)
    추정값 (Θ̂)    x̄    s²    s      p̂     p̂
- 표준오차(standard error, SE) : 추정했을 때, 실제 값하고 얼마나 차이가 나는지.
- 추정량 정의 :
    μ(X1,X2,···,Xn) = X -> 모평균μ을 추정하기 위한 도구(함수)를 X̄(표본평균)라고 부른다
    σ²(X1,X2,···,Xn) = S² -> 모분산σ²을 추정하기 위한 도구를 S²(표본분산)라고 부른다

# 점추정(point estimation)
- 좋은 추정량에 대한 판단 기준
    불편성(unbiascedness) : 추정량의 기대값이 모수를 정확히 반영
    -> 추정량의 기댓값이 모수를 반영해야 함
    최소분산성(efficiency) : 추정량의 분산이 작을수록 더 정확한 추정
    -> 분산이 작을수록 더 정확함
    일치성(consistency) : 표본 크기가 커질수록 추정량이 모수에 수렴
    -> 표본 크기가 커질수록 추정량이 모수에 수렴해야 함
- 편의(bias) : 어떤 모수 θ의 추정량을 Θ̂라고 할 때,
    -> Bias(Θ̂) = E[Θ̂] − θ
- 불편추정량(unbiased estimator) : 편의가 0이면 Θ̂는 불편성을 가짐.
    -> 이 때 Θ̂를 θ의 불편추정량이라고 함

ex) 5.3
- N(μ, σ²)를 따르는 정규모집단에서 추출한 확률표본 X₁, X₂, X₃에 대해 μ̂₁ = 1/3(X₁ + X₂ + X₃)가 μ의 불편추정량임을 보여라
-> sol) 불편추정량이 되려면, 추정량의 기댓값(E)이 추정하려는 모수(μ)와 같아야 함
        X₁, X₂, X₃는 모두 정규분포를 따름. 따라서 각각의 기댓값은 μ
        ∴ E[μ̂₁] = μ

ex) 5.4
- B(1. p)를 따르는 모집단에서 추출한 확률표본 X₁, X₂, ..., Xₙ에 대해 표본비율 p̂ = (∑Xᵢ)/n이 모비율 p의 불편추정량임을 보여라
-> sol) 베르누이 분포의 정의에 의해 E[Xᵢ] = p이다. 
        따라서 E[(∑Xᵢ)/n] = (n * p) / n = p
        ∴ E[p̂] = p

ex) 5.5
- N(μ, σ²)를 따르는 정규모집단에서 추출한 확률표본 X₁, X₂, ..., Xₙ의 표본분산 S²가 모분산 σ²의 불편추정량임을 보여라
-> sol) (n - 1) * S² / σ²는 χ²(n - 1)을 따름. X ~ χ²(v)일 때, E[X] = v. 위의 통계랑은 카이제곱분포의 정의에 따라 카이제곱분포를 따름
        확률변수 Y = X₁, X₂, ..., Xₙ
        E[Y] = (n - 1)/σ² * E[S²] = n - 1 
        ∴ E[S²] = σ²

ex) 5.6
- 일반 모집단에서 추출한 확률표본 X₁, X₂, ..., Xₙ에 대해 표본분산 S²가 모분산 σ²의 불편추정량임을 보여라
-> sol) goal : E[S²] = σ²임을 보이기
        S² = ∑(i = i ~ n) (X̄ - Xᵢ)² * (1/(n-1))
        ∑(i = i ~ n) (X̄ - Xᵢ)² 
            = ∑(i = i ~ n)((X̄ - μ) - (Xᵢ - μ))²
            = ∑(i = i ~ n) ((X̄ - μ)² - 2*(X̄ - μ)*(Xᵢ - μ) + (Xᵢ - μ)²)
            = n*(X̄ - μ)² - 2*(X̄ - μ)*∑(Xᵢ - μ) + ∑(Xᵢ - μ)²
            = n*(X̄ - μ)² - 2*(X̄ - μ)*n*(X̄ - μ) + ∑(Xᵢ - μ)²
            = n*(X̄ - μ)² - 2*n*(X̄ - μ)² + ∑(Xᵢ - μ)²
            = ∑(Xᵢ - μ)² - n*(X̄ - μ)²
        E[∑(X̄ - Xᵢ)²] 
            = ∑E[(Xᵢ - μ)²] - n*E[(X̄ - μ)²]
            = ∑σ² - n(σ²/n)
            = nσ² - σ²
            = (n - 1)σ²
        E[∑(X̄ - Xᵢ)²] * (1/(n-1)) = σ²
        ∴ E[S²] = σ²
        
- 불편추정량에 대한 생각 : 
    추정량이 불편추정량이면 가장 바람직한 추정량인가?
    -> 아님. 분산(산포 정도)가 매우 크다면 큰 오차 발생 가능
- 평균제곱오차(mean square error, MSE) : 모수 θ에 대한 추정량 Θ̂의 평균제곱오차
    -> MSE(Θ̂) = E[(Θ̂ - θ)²]
              = Var(Θ̂) + (Bias(Θ̂))²
    -> 불편추정량이 아닐 경우, 점추정량을 결정하는 기준으로 사용하기도 함
- 최소분산불편추정치(minimum variance unbiased estimator, MVUE) : 불편성을 만족하면서 최소의 분산을 가지는 값
    두 불편추정량 Θ̂₁, Θ̂₂에 대해
    1. Var(Θ̂₁) < Var(Θ̂₂)이면 Θ̂₁가 Θ̂₂보다 유효
    2. Θ̂₁에 대한 Θ̂₂의상대효율 : Var(Θ̂₁)/Var(Θ̂₂) 
- 일치추정량(consistent estimator) : 모수 θ의 표본 n개를 이용한 추정량 Θ̂ₙ = Θ̂(X₁, X₂, ..., Xₙ)이 임의의 ε > 0에 대해 다음을 만족
    lim(n -> ∞) P(|Θ̂ - θ| < ε) = 1  
    or lim(n -> ∞) P(|Θ̂ - θ| >= ε) = 0

    또는 lim(n -> ∞) E[Θ̂ₙ] = θ과 lim(n -> ∞) Var(Θ̂ₙ) = 0을 만족 (평균제곱오차가 0으로 수렴)

ex) 5.8
- 평균이 μ, 분산이 σ²인 모집단에서 추출한 확률표본 X₁, X₂, ..., Xₙ에 대해 표본평균 X̄가 μ의 일치추정량이고 표본분산 S²이 σ²의 일치추청량임을 보여라
-> sol) 1. X̄의 불편성과 최소분산성을 보일 것임
        Step 1 : 기댓값 확인. 표본평균의 기댓값은 모평균과 같음
            -> E[X̄] = μ
        ∴ X̄는 불편추정량
        Step 2 : 분산이 무한으로 갈 때의 값이 0인지 확인(최소분산 확인)
            -> lim(n -> ∞) Var(X̄) = lim σ² / n = 0
        ∴ X̄의 최소 분산은 0
        ∴ X̄는 μ의 일치추정량

        2. S²의 불편성과 최소분산성
        Step 1 : 기댓값
            -> E[S²] = σ² (위에서 증명)
        ∴ S²는 불편추정량
        Step 2 : 분산의 분산이 무한으로 갈 때 0인지 확인
            -> 어떤 통계량의 분산은 Var(임의의 다른 통계량) / n로 정의될 수 있음
            S² = ∑(i = i ~ n) (X̄ - Xᵢ)² * (1/(n-1))
                여기에서, (X̄ - Xᵢ)² = Zᵢ라고 정의.
               = (1/(n-1)) * ∑Zᵢ
            lim(n -> ∞) Var(S²) = lim Var((1/(n-1)) * ∑Zᵢ)
                여기에서, n이 무한으로 가기 때문에 (1/(n-1)) * ∑Zᵢ는 Z̄로 근사할 수 있엄
            = lim Var(Z̄) = lim Var(Z) / n = 0
        ∴ S²의 최소 분산은 0
        ∴ S²는 σ²의 일치추정량

# 적률추정법(method of moments​​)
- 적률(moment) : 확률변수 X의 r차 적률이라고 함
    -> μᵣ = E[Xʳ]
- 중심적률(central moment) 
    -> μᵣᶜ = E[(X - μ)ʳ]
- 주요 적률과 의미
    1차 적률 : μ₁ = E[X] -> 평균
    2차 중심적률 : μ₂ᶜ = E[(X - μ)²] -> 분산
    3차 중심적률 : 왜도, 4차 중심적률 : 첨도
- 표본적률(sample moment) 
    -> μ̂̂ᵣ = (1/n) * ∑(i = 1 ~ n)Xᵢʳ
- 모적률(population moment)
    -> μᵢ = E[Xⁱ]
- 적률추정량(method of moments​​ estimator) : 모수를 이루는 적률들에 대응하는 표본적률의 결합으로 표현되는 추정량 Θ̂
    추정하는 모수 θ가 모적률 μ₁, μ₂, ..., μₙ의 결합으로 표현될 때,
    -> θ = h(μ₁, μ₂, ..., μₙ)일 때,
    모수 θ의 표본 n개를 이용한 추정량 Θ̂ₙ = Θ̂(X₁, X₂, ..., Xₙ)이 아래 통계량에 의해 추정되면 Θ̂를 적률추정량이라고 함
    -> Θ̂(X₁, X₂, ..., Xₙ) = h(μ̂₁, μ̂₂, ..., μ̂ₙ)

ex) 5.9







  
