통계적 추정
가설검정
-> 두 개가 메인

chapter 05

# 통계적 추론
- 고려 중인 모집단으로부터 추출한 표본을 기초로 모집단이나 모수를 추정하고 검정
- 모수(parameter) : 모집단의 특성을 나타내는 것
- 통계량(statistic) : 표본의 특성을 나타내는 것
- 추정(estimation) : 모수의 참값으로 추측되는 값을 구하는 과정
- 점추정(point estimation) : 모수의 참값이라고 추측되는 하나의 값을 구하는 것
- 구간추청(interval estimation) : 모수의 참값을 포함할 것이라고 추측되는 구간을 구하는 것
- 가설검정(hypothesis testing) : 모수에 대한 추정의 옳고 그름을 판단하는 과정
- 추정 방법
    고전적 방법(classical method) : 확률표본에 기반하여 모수를 추정
    베이지안 방법(bayesian method) : 표본 정보와 함께 모수의 사전 확률분포를 이용
- 추정값 : 실제 표본 데이터를 적용해 얻은 수치 결과
- 추정량 : 표본 통계량을 이용해 모수를 추측하는 계산식(아래 표의 원소를 모두 포함)
      구분       평균  분산  표준편차  비율  상관계수
    모집단 (θ)    μ    σ²    σ      p     ρ      (모수)
    통계량 (Θ̂)    X̄    S²    S      p̂     p̂      (추정량, 세타 대문자 써야 함)
    추정값 (Θ̂)    x̄    s²    s      p̂     p̂
- 표준오차(standard error, SE) : 추정했을 때, 실제 값하고 얼마나 차이가 나는지.
- 추정량 정의 :
    μ(X1,X2,···,Xn) = X -> 모평균μ을 추정하기 위한 도구(함수)를 X̄(표본평균)라고 부른다
    σ²(X1,X2,···,Xn) = S² -> 모분산σ²을 추정하기 위한 도구를 S²(표본분산)라고 부른다

# 점추정(point estimation)
- 정의 : 모수의 참값이라고 추측되는 하나의 값을 구하는 것
- 좋은 추정량에 대한 판단 기준
    불편성(unbiascedness) : 추정량의 기대값이 모수를 정확히 반영
    -> 추정량의 기댓값이 모수를 반영해야 함
    최소분산성(efficiency) : 추정량의 분산이 작을수록 더 정확한 추정
    -> 분산이 작을수록 더 정확함
    일치성(consistency) : 표본 크기가 커질수록 추정량이 모수에 수렴
    -> 표본 크기가 커질수록 추정량이 모수에 수렴해야 함

# 점추정 - 불편추정(unbiased estimation)
- 편의(bias) : 어떤 모수 θ의 추정량을 Θ̂라고 할 때,
    -> Bias(Θ̂) = E[Θ̂] − θ
- 불편추정량(unbiased estimator) : 편의가 0이면 Θ̂는 불편성을 가짐.
    -> 이 때 Θ̂를 θ의 불편추정량이라고 함

ex) 5.3
- N(μ, σ²)를 따르는 정규모집단에서 추출한 확률표본 X₁, X₂, X₃에 대해 μ̂₁ = 1/3(X₁ + X₂ + X₃)가 μ의 불편추정량임을 보여라
-> sol) 불편추정량이 되려면, 추정량의 기댓값(E)이 추정하려는 모수(μ)와 같아야 함
        X₁, X₂, X₃는 모두 정규분포를 따름. 따라서 각각의 기댓값은 μ
        ∴ E[μ̂₁] = μ

ex) 5.4
- B(1. p)를 따르는 모집단에서 추출한 확률표본 X₁, X₂, ..., Xₙ에 대해 표본비율 p̂ = (∑Xᵢ)/n이 모비율 p의 불편추정량임을 보여라
-> sol) 베르누이 분포의 정의에 의해 E[Xᵢ] = p이다. 
        따라서 E[(∑Xᵢ)/n] = (n * p) / n = p
        ∴ E[p̂] = p

ex) 5.5
- N(μ, σ²)를 따르는 정규모집단에서 추출한 확률표본 X₁, X₂, ..., Xₙ의 표본분산 S²가 모분산 σ²의 불편추정량임을 보여라
-> sol) (n - 1) * S² / σ²는 χ²(n - 1)을 따름. X ~ χ²(v)일 때, E[X] = v. 위의 통계랑은 카이제곱분포의 정의에 따라 카이제곱분포를 따름
        확률변수 Y = X₁, X₂, ..., Xₙ
        E[Y] = (n - 1)/σ² * E[S²] = n - 1 
        ∴ E[S²] = σ²

ex) 5.6
- 일반 모집단에서 추출한 확률표본 X₁, X₂, ..., Xₙ에 대해 표본분산 S²가 모분산 σ²의 불편추정량임을 보여라
-> sol) goal : E[S²] = σ²임을 보이기
        S² = ∑(i = i ~ n) (X̄ - Xᵢ)² * (1/(n-1))
        ∑(i = i ~ n) (X̄ - Xᵢ)² 
            = ∑(i = i ~ n)((X̄ - μ) - (Xᵢ - μ))²
            = ∑(i = i ~ n) ((X̄ - μ)² - 2*(X̄ - μ)*(Xᵢ - μ) + (Xᵢ - μ)²)
            = n*(X̄ - μ)² - 2*(X̄ - μ)*∑(Xᵢ - μ) + ∑(Xᵢ - μ)²
            = n*(X̄ - μ)² - 2*(X̄ - μ)*n*(X̄ - μ) + ∑(Xᵢ - μ)²
            = n*(X̄ - μ)² - 2*n*(X̄ - μ)² + ∑(Xᵢ - μ)²
            = ∑(Xᵢ - μ)² - n*(X̄ - μ)²
        E[∑(X̄ - Xᵢ)²] 
            = ∑E[(Xᵢ - μ)²] - n*E[(X̄ - μ)²]
            = ∑σ² - n(σ²/n)
            = nσ² - σ²
            = (n - 1)σ²
        E[∑(X̄ - Xᵢ)²] * (1/(n-1)) = σ²
        ∴ E[S²] = σ²
        
- 불편추정량에 대한 생각 : 
    추정량이 불편추정량이면 가장 바람직한 추정량인가?
    -> 아님. 분산(산포 정도)가 매우 크다면 큰 오차 발생 가능
- 평균제곱오차(mean square error, MSE) : 모수 θ에 대한 추정량 Θ̂의 평균제곱오차
    -> MSE(Θ̂) = E[(Θ̂ - θ)²]
              = Var(Θ̂) + (Bias(Θ̂))²
    -> 불편추정량이 아닐 경우, 점추정량을 결정하는 기준으로 사용하기도 함
- 최소분산불편추정치(minimum variance unbiased estimator, MVUE) : 불편성을 만족하면서 최소의 분산을 가지는 값
    두 불편추정량 Θ̂₁, Θ̂₂에 대해
    1. Var(Θ̂₁) < Var(Θ̂₂)이면 Θ̂₁가 Θ̂₂보다 유효
    2. Θ̂₁에 대한 Θ̂₂의상대효율 : Var(Θ̂₁)/Var(Θ̂₂) 
- 일치추정량(consistent estimator) : 모수 θ의 표본 n개를 이용한 추정량 Θ̂ₙ = Θ̂(X₁, X₂, ..., Xₙ)이 임의의 ε > 0에 대해 다음을 만족
    lim(n -> ∞) P(|Θ̂ - θ| < ε) = 1  
    or lim(n -> ∞) P(|Θ̂ - θ| >= ε) = 0

    또는 lim(n -> ∞) E[Θ̂ₙ] = θ과 lim(n -> ∞) Var(Θ̂ₙ) = 0을 만족 (평균제곱오차가 0으로 수렴)

ex) 5.8
- 평균이 μ, 분산이 σ²인 모집단에서 추출한 확률표본 X₁, X₂, ..., Xₙ에 대해 표본평균 X̄가 μ의 일치추정량이고 표본분산 S²이 σ²의 일치추청량임을 보여라
-> sol) 1. X̄의 불편성과 최소분산성을 보일 것임
        Step 1 : 기댓값 확인. 표본평균의 기댓값은 모평균과 같음
            -> E[X̄] = μ
        ∴ X̄는 불편추정량
        Step 2 : 분산이 무한으로 갈 때의 값이 0인지 확인(최소분산 확인)
            -> lim(n -> ∞) Var(X̄) = lim σ² / n = 0
        ∴ X̄의 최소 분산은 0
        ∴ X̄는 μ의 일치추정량

        2. S²의 불편성과 최소분산성
        Step 1 : 기댓값
            -> E[S²] = σ² (위에서 증명)
        ∴ S²는 불편추정량
        Step 2 : 분산의 분산이 무한으로 갈 때 0인지 확인
            -> 어떤 통계량의 분산은 Var(임의의 다른 통계량) / n로 정의될 수 있음
            S² = ∑(i = i ~ n) (X̄ - Xᵢ)² * (1/(n-1))
                여기에서, (X̄ - Xᵢ)² = Zᵢ라고 정의.
               = (1/(n-1)) * ∑Zᵢ
            lim(n -> ∞) Var(S²) = lim Var((1/(n-1)) * ∑Zᵢ)
                여기에서, n이 무한으로 가기 때문에 (1/(n-1)) * ∑Zᵢ는 Z̄로 근사할 수 있엄
            = lim Var(Z̄) = lim Var(Z) / n = 0
        ∴ S²의 최소 분산은 0
        ∴ S²는 σ²의 일치추정량

# 점추정 - 적률추정법(method of moments​​)
- 적률(moment) : 확률변수 X의 r차 적률이라고 함
    -> μᵣ = E[Xʳ]
- 중심적률(central moment) 
    -> μᵣᶜ = E[(X - μ)ʳ]
- 주요 적률과 의미
    1차 적률 : μ₁ = E[X] -> 평균
    2차 중심적률 : μ₂ᶜ = E[(X - μ)²] -> 분산
    3차 중심적률 : 왜도, 4차 중심적률 : 첨도
- 표본적률(sample moment) 
    -> μ̂̂ᵣ = (1/n) * ∑(i = 1 ~ n)Xᵢʳ
- 모적률(population moment)
    -> μᵢ = E[Xⁱ]
- 적률추정량(method of moments​​ estimator) : 모수를 이루는 적률들에 대응하는 표본적률의 결합으로 표현되는 추정량 Θ̂
    추정하는 모수 θ가 모적률 μ₁, μ₂, ..., μₙ의 결합으로 표현될 때,
    -> θ = h(μ₁, μ₂, ..., μₙ)일 때,
    모수 θ의 표본 n개를 이용한 추정량 Θ̂ₙ = Θ̂(X₁, X₂, ..., Xₙ)이 아래 통계량에 의해 추정되면 Θ̂를 적률추정량이라고 함
    -> Θ̂(X₁, X₂, ..., Xₙ) = h(μ̂₁, μ̂₂, ..., μ̂ₙ)

ex) 5.9
- 확률표본 X₁, X₂, ..., Xₙ을 모집단 X ~ B(m, p)에서 추출하였을 때, θ₁ = mp와 θ₂ = mp(1 - p)의 적률추정량을 구해라
-> sol) 1. mp는 이항분포의 평균(1차 적률).
        μ̂₁ = X̄ 
        ∴ θ̂₁ = X̄ = (1/n) * ∑(i = 1 ~ n) Xᵢ

        2. mp(1 - p)는 이항분포의 분산(2차 적률 - 1차 적률의 제곱)
        μ₂ - μ₁² = mp - mp²
        ∴ θ̂₂ = mp̂(1 - p̂) = X̄(1 - X̄/m)

# 점추정 - 최대가능도 추정법(maximum likehood estimate, MLE)
- 우도함수(likehood function) : 모집단이 미지의 모수 θ에 의존하는 f(x; θ)를 따르고, 확률표본 X₁, X₂, ..., Xₙ으로부터 구성된 관측값 x₁, x₂, ..., xₙ에 대해
    L(θ; x₁, x₂, ..., xₙ) = fX₁, X₂, ..., Xₙ(x₁, x₂, ..., xₙ; θ)
    과 같은 결합확률밀도함수 L(θ).
- 최대가능도 추정법(maximum likehood estimate, MLE) : 우도함수 L(θ)를 최대로 하는 θ값에 대한 추정치 θ̂를 구하는 것
    using : 1. 관심있는 모수에 대한 정보 부족할 떄
            2. 모집단의 추종 확률분포는 알지만, 구체적인 모수값은 모를 때
            3. 합리적인 추정량을 선택하기 어려울 때
    prop : 1. 우도함수가 미분가능히면 이를 최대로 하는 θ는 L'(θ) = 0을 만족 (당연?)
           2. 확률표본들이 서로 독립이며 같은 분포를 가진다면 L(θ) = Π(k = 1 ~ n) f(xₖ; θ)를 만족

ex) 5.11
- X₁, X₂, ..., Xₙ을 X ~ Pois(θ)로부터 추출한 표본이라고 할 때, θ에 대한 최대가능도 추정량은?
-> sol) 1. f(x;θ)(pdf) : e⁻ᶿ * θˣ/x!
        2. 위의 확률변수들은 독립. 따라서 우도함수는 확률밀도함수의 곱으로 표현된다.
        ∴ L(θ) = Π(k = 1 ~ n) e⁻ᶿ * θ^xₖ/xₖ!
               = e⁻ⁿᶿ(∑θ^xₖ) / Πxₖ!
        3. 미분계수가 0인 곳을 찾아야 하는데, 미분하기 어려우니 ln을 취함
        ln L(θ) = l(θ) = (-nθ) + lnθ * ∑xₖ + ∑ln(xₖ!)
        l'(θ) = -n + (1/θ)∑xₖ 
        4. 여기에서, 미분계수 = 0 계산하여 θ 추출
        ∴ polar point of θ = (1/n)∑xₖ
        그런데, 여기에서 (1/n)∑xₖ. 이는 평균(X̄)임을 익히 알고 있음
        ∴ MLE θ̂ = X̄

# 구간추정(interval estimation)
- 정의 : 모수의 참값을 포함할 것이라고 추측되는 구간을 구하는 것
- 신뢰구간(confidence interval) : 모수를 값이 아니고 고려된 구간으로 나타낸 것 
- 오차한계(error bound) : 두 구간의 차의 절댓값의 반 (|b - a| / 2)

# 구간추정 - 모평균의 신뢰구간 추청 
    case A. σ²를 알 때
        1. 정규모집단인 경우 -> Z 통계량 사용
        2. 비정규모집단이며 n >= 30인 경우 -> Z 통계량으로 근사
    case B. σ²를 모를 때(s²으로 대신 사용)
        1. 정규 -> t 통계량 사용
        2. 비정규, 30 -> Z 통계량으로 근사
- σ²이 알려진 모집단에서 모평균 μ의 100(1 - α)%의 신뢰구간(표준정규분포 이용):
    x̄ - z_α/2 * σ / √n < μ < x̄ + z_α/2 * σ / √n

    -> z 파이썬 함수 : norm.ppf(신뢰구간, 0, 1) or Z.ppf(신뢰구간)

ex) 5.15
- 모집단이 N(μ, 64)의 정규분포를 따를 때, 크기가 81인 표본에 대해 X̄ = 100이었다면 μ에 대한 95% 신뢰구간은?
-> sol) 1. sigma = np.sqrt(64)             (σ)
           xbar = 100                      (주어진 평균, X̄)
           n = 81                          (표본 크기)
           zalp = norm.ppf(1-0.025, 0, 1)  (z_α/2. 95%신뢰구간이니 반 나눠서 0.025), (0, 1 매개변수는 정규분포에서 평균이 0, 표준편차가 1인 Z(표분정규분포)를 사용한다는 뜻)
        
        2. Lint = xbar - zalp * sigma / np.sqrt(n)    (뺌)
           Rint = xbar + zalp * sigma / np.sqrt(n)    (더함)

- σ²이 알려지지 않은 모평균의 신뢰구간(t분포 이용):
    x̄ - t_α/2 * (n - 1) * s / √n < μ < x̄ + t_α/2 * (n - 1) * s / √n

    -> t 파이썬 함수 : t.ppf(신뢰구간, 자유도)
    -> 표본추출 함수 : norm.rvs(표본평균, 표준편차, 표본크기), 배열 return

ex) 5.18
- μ = 240, σ = 25인 정규난수 11개를 생성하여 정수로 반올림한 결과에 대해 신뢰수준 95%, 99%인 경우에 대한 모평균 μ의 신뢰구간을 구하는 파이썬 프로그램
-> sol) 1. mu_real = 240               # 실제 모평균 (난수 생성용)
           sigma_real = 25             # 실제 모표준편차 (난수 생성용)
           n = 11                      # 표본 크기 (소표본)
           sample = np.round(norm.rvs(loc=mu_real, scale=sigma_real, size=n))
           x_bar = np.mean(sample)          # 표본평균
           s = np.std(sample, ddof=1)       # 표본표준편차 (자유도 n-1 적용)

        2. def confidence_interval_t(confidence_level, n, x_bar, s):
            alpha = 1 - confidence_level
            df = n - 1  # 자유도

            t_val = t.ppf(1 - alpha/2, df) 
            error = t_val * (s / np.sqrt(n))
    
            return x_bar - error, x_bar + error

        3. ci_95 = confidence_interval_t(0.95, n, x_bar, s)
           ci_99 = confidence_interval_t(0.99, n, x_bar, s)

- σ²이 알려지지 않고 대표본(n ≥ 30)인 경우 모평균의 신뢰구간(표준정규분포에서 σ를 s로 대체):
    x̄ - z_α/2 * s / √n < μ < x̄ + z_α/2 * s / √n

# 구간추정 - 모분산, 모비율의 신뢰구간 추정
- σ²이 알려지지 않은 정규모집단에서 얻은 표본에 대해 σ²의 100(1 - α)%신뢰구간(χ² 이용):
    (n - 1)s² / χ²_α/2(n - 1) ≤ σ² ≤ (n - 1)s² / χ²_1-α/2(n - 1) -> χ² 파이썬 함수 : chi2.ppf(신뢰구간, 자유도)

    -> χ² 파이썬 함수 : chi2.ppf(신뢰구간, 자유도)

ex) def confidence_interval_of_population_variance(sample, confid_level):
        std = np.std(sample)    (표준편차)
        n = len(sample) - 1     (자유도)
        lc = n*std**2/chi2.ppf(1-confid_level/2, n)
        rc = n*std**2/chi2.ppf(confid_level/2, n)
        return np.array([lc, rc]) (신뢰구간)
        
- 두 정규모집단에서 얻은 표본에 대해 모분산 비의 100(1 - α)%신뢰구간(f분포 이용):
    s₁²/s₂² / f_α/2(v₁, v₂) ≤ σ₁²/σ₂² ≤ s₁²/s₂² / f_1-α/2(v₁, v₂)

    -> f_x(v₁, v₂) : F-분포의 오른쪽 꼬리 면적이 x가 되는 값
    -> f 파이썬 함수 : f.ppf(신뢰구간, 자유도1, 자유도2)

ex) def confidence_interval_of_ratio_of_population_variance(sample1, sample2, confid_level):
        n1, n2 = len(sample1) - 1, len(sample2) - 1
        v1, v2 = np.var(sample1, ddof = 1), np.var(sample2, ddof = 1) #ddof는 그냥 분산 구할 때 쓴다~
        low = (v1/v2) / f.ppf(1 - confid_level/2, n1, n2)
        up = (v1/v2) / f.ppf(confid_level/2, n1, n2)
        return np.array([low, up]) (신뢰구간)

- 모수가 p인 베르누이 분포로부터 얻은 n개의 확률표본에 대한 p의 100(1 - α)%의 근사적 신뢰구간:
    p̂ - z_α/2√(p̂(1-p̂)/n) < p < p̂ + z_α/2√(p̂(1-p̂)/n)

    -> p̂ = x/n = ∑(i = 1 ~ n)xᵢ/n이고 n - x ≥ 5, x ≥ 5인 경우에 적용

ex) 5.22
- A 후보의 득표율을 예측하기 위해 50명을 임의로 추출해 조사한 결과 25명이 A후보를 지지했을 떄, 지지율 p에 대한 95% 신뢰구간을 구하여라
-> sol) 1. n = 50
           p = 0.5
           confid_level = 0.95
           alpha = 1 - confid_level
           error = abs(norm.ppf(alpha/2, 0, 1)) * (p*(1-p)/n)**(0.5)  
           # norm.ppf(alpha/2, 0, 1)는 음수를 반환. norm.ppf(1 - alpha/2, 0, 1) or abs(norm.ppf(alpha/2, 0, 1))를 써야 함

        2. low = p - error
           up = p + error

        3. interval = np.array([low, up])

# 표본크기 계산
- 신뢰수준이 1 - α이고 오차한계를 δ로 제한할 때 n의 최솟값
    1. σ²을 아는 정규모집단 : n ≥ (z_α/2 * σ/δ)²
    2. σ²을 모르는 정규모집단 : n ≥ (t_α/2(n - 1) * σ/δ)²
    3. σ²을 모르는 (비)정규모집단, 대표본인 경우 : n ≥ (z_α/2 * s/δ)²

ex) 5.24
- N(μ, 25)를 따르는 모집단에 대해, μ에 대한 95% 신뢰구간의 추정에서 오차한계 δ = 1.5로 제한할 때 필요한 표본크기는?
-> sol) alpha = 0.5
        delta = 1.5
        sigma = 5
        min_n = (norm.ppf(1 - alpha/2) * delta * sigma)**2

- 베르누이 분포(1, p)를 따르는 모집단의 모비율 p의 점추정값이 p̂이고 신뢰수준이 1 - α일 때, 오차한계 δ로 제한하는 n
    n ≥ p̂(1 - p̂) * (z_α/2 / δ)²

ex) 5.26
- 500개의 표본에 대해 350개가 성공일 때, p의 점추정값이 95%에서 오차한계를 0.02로 제한하기 위한 표본의 크기와
    예비 표본조사 없이 p의 점추정값이 신뢰수준 95%에서 δ = 0.03으로 제한하기 위한 표본의 크기는?
-> sol) 1 - 1. alpha = 0.5
               n = 500
               x = 350
               p = x/n
               delta = 0.02
        1 - 2. min_n = p * (1 - p) * (norm.ppf(1 - alpha/2) / delta)**2

        2 - 1. 사전 정보가 없음. 그럴 때는 점추정값을 0.5로 가정
               p = 0.5
               delta = 0.03
        2 - 2. min_n = p * (1 - p) * (norm.ppf(1 - alpha/2) / delta)**2


chapter 06

# 귀무가설과 대립가설
- 추정은 직접적인 통계적 추론. 가설검정은 간접적인 추론 방법
- 가설검정 순서 : 1. 모집단의 특성에 대한 가설과 검정통계량 설정
               2. 검정의 유의수준(α)를 정한다
               3. 표본의 검정통계량을 계산한다
               4. 표본의 검정통계량에 대한 p-value를 구하여 가설에 대한 결론을 내린다
- 귀무가설(null hypothesis) : 기존에 옳다고 알려진 사실에 해당하는 가설
    notation : H₀
- 대립가설(alternative hypothesis) : 자료에서 얻은 증거를 바탕으로 입증하고자 하는 새로운 주장
    notation : H₁ or Hₐ
    순서 : 대립가설 -> 귀무가설

ex) 6.1
- 어떤 의약품의 기존 치료율은 p₀ = 0.3이고 신약을 개발하여 치료율이 개선되었는지를 확인하기 위해 신약을 투여한 25명을 조사한 결과, 
    12명 이상이 치료되었을 때, 가설검정을 시행하기 위한 귀무가설과 대립가설을 설정
-> sol) H₀ : p = 0.3 or p₀ ≦ 0.3
         신약의 치료율은 기존 치료율(0.3)과 차이가 없다 (개선되지 않았다)
        H₁ : p > 0.3
         신약의 치료율은 기존 치료율(0.3)보다 개선되었다

ex) 6.2
- 기존 건전지의 평균수명 μ₀ = 2000이고 새로운건 그걸 넘는다고 주장. 
    새로운 64개를 무작위 추출하여 표본평균 X̄를 근거로 하여 판단할 때, 귀무가설과 대립가설 설정
-> sol) H₀ : μ ≦ 2000
         새로운 배턱리의 평균 수명이 2000보다 작거나 같다
        H₁ : μ > 2000
         새로운 배터리의 평균 수명이 200보다 크다 

# 검정통계량과 기각역
- 검정통계량(test statistic) : 확률표본에 근거하여 H₀, H₁ 중 어느 하나를 채택할 때 사용되는 통계량
- 채택역 : 귀무가설을 채택하는 관측값 영역
- 기각역 : 대립가설을 채택하는 관측값 영역
- 임계값(critical value) : 채택역과 기각역을 구분하는 값

# 검정오류와 유의수준
사실\검정효과    H₀을 기각하지 않음    H₀기각
---------------------------------------
H₀가 참           옳은 결정        1종 오류
---------------------------------------
H₁가 참           2종 오류         옳은 결정
       
- 유의수준(significant level) : 1종 오류를 범할 확률 α에 대해 허용되는 α의 최대값
- 검정력(statistic power) : 2종 오류를 범할 확률 β에 대해 1 - β
- p-value, 유의확률(significance probability) : 귀무가설이 참이라는 가정하에
    관측값으로부터 계산된 통계량의 값이 H₀을 지지하는 최대 확률. 즉, H₀를 기각할 최소의 유의수준
    usage : p-value ≦ α이면 H₀을 기각
            p-value > α이면 H₀을 기각할 수 없음

ex) 6.3
- 예제 6.1에서 1종 오류를 범할 확률인 최소한의 유의수준 α를 구하여라. 즉, p-value를 구하여라
-> sol) 1. 귀무가설과 대립가설 가져오기
         H₀ : p₀ ≦ 0.3
         H₁ : p > 0.3
        2. 치료된 사람의 수 X에 대해 치료됨/치료 안 됨. 두 가지로 나뉨. 
         ∴ X ~ B(25, 0.3)
        3. p-value를 조건부 확률로 정의함
         α = P(관측값이 기각 | H₀) = P(X ≧ 12 | p = 0.3) = 1 - P(X ≦ 11 | p = 0.3)
          -> p_value = 1 - stats.binom.cdf(11, n, p)
         ∴ 0.04424


            




  
