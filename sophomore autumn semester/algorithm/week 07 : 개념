chapter 1

# stable matching problem
- 설명 : 
    남여 쌍이 서로에 대한 선호도를 쭉 씀
    여기에서 unstable pair가 없게 해야 함
    
    unstable pair : 어떤 파트너가 아닌 남여가 서로를 현재 파트너보다 선호하는 쌍
    고찰점 : 언제나 stable matching이 존재하는가? -> yes. by the under algorithm

# Gale–Shapley's Propose-and-Reject algorithm
- 알고리즘 설명 : 
    1. 어떤 남자가 free이고 아직 프로포즈 하지 않은 여자가 있을 때까지 반복
    2. 남자 m을 고름
    3. 남자 m이 프로포즈하지 않은 여자 집단 중 가장 선호하는 여자 w를 고름
    4-1. 여자가 free라면, engage함
    4-2. w의 파트너 m'의 선호도가 m보다 낮으면, engage함
    4-3. 거절함
- 특징 : 
    men-optimal assignment임

# hospital–residents matching problem
- 설명 :
    병원은 수용 가능한 인원이 한 명이 아님
    따라서, 조금 상황이 다름
- 해결 :
    게일 셰플리 그대로 적용하면 됨. 남자에 병원 넣어서 수용 가능한 인원만큼 다 뽑음

# weighted interval shceduling
- 설명 : 시작시간, 끝나는 시간, 가중치가 있는 element들이 주어졌을 때,
        가장 가중치가 높은 중복되지 않는 subset을 찾아라
- 해결 : dp해야함. OPT(j) = max(wj ​+ OPT(p(j)), OPT(j − 1))

# bipartite matching
- 설명 : 이분 그래프에서 최대 매칭(간선 수 최대) 찾기
- 해결 : 최대 유량 쓰셈

# independent set
- 설명 : 그래프에서 서로 인접하지 않은 정점들의 최대 크기 부분집합 찾기
- 해결 : 백트래킹 돌리셈

# competitive facility location
- 설명 : 각 노드에 가중치가 있는 그래프에서 두 플레이어가 번갈아 노드를 선택(이미 선택된 노드의 이웃은 선택 불가). 
  목표는 자신의 총 가중치 최대화
- 해결 : PSPACE-complete


chapter 2

# computational tractability
- brute force : checks every possible solution. 
    특징 : 보통 2^n정도 걸림
- Polynomial-time : 다항시간. 위의 부르트포스는 지수시간임. n^2같은거
    note. 어떤 지수시간 알고리즘은 잘 돌아가기도 함

# asymptotic order of growth
- bounds
    upper bound (O)
    lower bound (Ω)
    tight bound (Θ)
- notation
    ex. T(n) = O(f(n)) -> T(n)이 f(n)의 상한선 이하로 성장함
- properties : 
    Transitivity (전이성): f = O(g), g = O(h) → f = O(h)
    Additivity (가법성): : f = O(h), g = O(h) → f + g = O(h)


chapter 3

# normal interval scheduling
- 설명 : 일들의 시작시간 끝나는 시간이 주어짐.
        최대한 많은 일을 해결하시오. 겹치지 않게
- 해결 : 일이 끝나는 시간 기준으로 정렬해서 겹치지 않게 그리디
- 복잡도 : nlogn

# interval partitioning
- 설명 : 강의 시작시작, 끝나는 시간 주어짐.
        모든 강의는 해야 하는데, 몇 개의 강의실 쓰냐.
- 해결 : 강의를 시작시작 기준으로 정렬. 가능한 강의실이 있으면 배정, 없으면 새 강의실 추가.
- 복잡도 : nlogn 

# scheduling to minimize lateness
- 설명 : task의 마감시간, 걸리는 시간이 주어짐. 늦는 것을 최소화해야 함
- 해결 : 마감기한이 빠른 순으로 처리해야 최적
- 복잡도 : n... 인데 정렬은 안 끼냐?

# optimal caching
- 설명 : 캐시가 있고, 그 캐시가 담아줄 데이터를 결정하여 cache miss를 최소화
- 해결 : farthest-in-future. 
        캐시에 넣을 때는 그냥 계속 넣음
        꽉 찬 상태라면 캐시의 element 중 가장 나중에 필요한 것을 evict함

# shortest path in gragh
- 설명 : 방향 그래프에서 시작에서 도착까지의 최단거리 찾기
- 해결 : dijkstra
- 복잡도 : implementation by.
    array : n^2
    binary heap : m long n
    d-way heap : m log m/n n
    fib heap : m + nlogn


chapter 4

# huffman
- 문제상황 :
    32개의 심볼을 사용하는 텍스트가 있음(알파벳, 공백, 몇 기능적 기호들)
    이것들 중 자주 나오는 것들이 있는데 그걸 사용하여 압축하고 싶음

- fixed length encoding : 32개니까 2^5만큼 비트필드를 써서 그대로 나열
- prefix code : A의 코드가 B의 코드의 앞부분(prefix)이 되면 안 됨.
    따라서, 읽는 것에 혼동이 발생하지 않고 빈도가 높은 것을 짧은 것에 할당하면 압축이 잘 됨
    트리 표현 : binary tree의 leaf를 이용하여 어떻게 매핑할지 간단하게 정할 수 있음 (왼쪽 0, 오른쪽 1로 설정)
    최적 코드 : 평균 비트 수(ABL) 가 최소
    최적 트리 : full binary tree (모든 내부 노드가 자식 2개)
- huffman encoding : lowest frequency 문자 2개를 묶어 가짜 문자(ω)로 만들고 반복해서 바텀업
    time complexity : nlogn. 
    ABL(average bits per letter) = Σ(빈도 × 비트 길이)
    과정 :
      1. S를 복사한 S'을 만들어 가장 낮은 빈도의 노드 x(ex. x = 2), y(3)를 꺼냄
      2. S'에 두 빈도를 합한 w(5)를 넣음
      3. 노드 w의 두 자식으로 x와 y를 넣음
      4. 위 과정을 반복
      note. 재귀적으로 이루어지며, 종료조건은 |S| = 2, 함수는 트리를 반환함
- 허프만 트리 최적 증명 :
    predetermined point by observation. 최저 빈도 두 문자는 최적 트리에서 형제 리프가 될 수 있음
    base : 문자가 2개면 루트와 두 리프가 유일
    IH(귀납가정) : 허프만 알고리즘이 만든 트리 T'은 최적
    모순법
     1. 허프만보다 ABL이 더 작은 Z가 있다고 가정
     2. 빈도가 가장 낮은 x, y를 리프로 가지는 최적형을 고려
     3. Z에서 x, y를 제거하고 w로 대체하면 Z'을 얻음
     4. ABL(Z′) = ABL(Z) − fω, ABL(T′) = ABL(T) − fω
     5. 가정상 ABL(Z') < ABL(T). 
     6. 근데 이건 귀납가정과 모순이다. 
     따라서 모순이니 허프만이 최적

# mst (minimun spanning tree)
- 정의 : 모든 정점을 잇는 간선의 가중치가 가장 작은 트리
- 응용 : Network design. 전화선, 전력선, 수도관, TV 케이블, 도로, 컴퓨터 네트워크 등. 
        Cluster analysis (클러스터링) 에도 사용됨.
- 생성 
    kruskal : 모든 간선을 정렬하고 작은 것부터 사이클이 생기지 않으면 연결. 
    prim : 그냥 하나에서 시작해서 다익스트라 돌리고 사이클 생기기 전까지 함
    reverse-delete : 간선 가중치가 큰 것부터 지우면서 연결이 유지되면 지움.
    note. 모두 m lon n
    
# clustering
- 설명 : 객체 집합을 유사한 특성을 가진 그룹으로 분류하는 것
- goal : 다른 클러스터는 멀,같은 클러스터 내부는 가깝게 하는 것
- application : 
    무선 네트워크 라우팅
    유전자 발현 패턴 탐지
    문서 분류, 이미지 검색
    천체(별, 은하, 퀘이사) 분류
- 방법 : n개의 객체를 k개로 나눈다고 하였을 때.
    1. mst를 일단 만듦.
    2. 거기에서 비용이 가장 큰 k - 1개의 간선을 제거
    3. 그러면 최대 spacing의 k-clustering이 됨


chapter 5

# merge sort
- 설명 : 다 나눔. 그리고 합칠 때 비교해서 다 정렬
- divide : 배열을 반으로 나눔
- conquer : 각 절반을 재귀적으로 정렬
- 알잖아 

# counting inversions
- inversion: i < j인데 aᵢ > aⱼ인 쌍.
- 목표: 배열의 “정렬 정도(sortedness)” 측정.
- 방법 : 
    1. 배열을 둘로 나눔
    2. 각각의 반쪽에서 inversion을 count함
    3. 오른쪽에서 왼쪽으로의 inversion을 count함
    4. 더함
    note. 만약 두 쌍이 모두 정렬되어 있다고 한다면, 오른쪽에서만 왼쪽에 대해 inversion을 세면 됨
- 복잡도 : n longn

# closest pair of point
- 목표 : 평면 상의 n개의 점에 대해, 두 점 사이의 최소 유클리드 거리 찾기
- application : 그래픽스, 컴퓨터 비전, GIS, 항공 교통, 생물정보학
- 방법 :
    1. 세로선 L을 그어 반으로 나눔
    2. 각각의 반에서 가장 가까운 포인트를 찾음
    3. 그 두 최솟값 중 작은 것을 d라고 할 때, L로부터 d보다 멀리 있는 것들을 모두 지움
    4. 이제 남은 것들 중 가장 짧은 것이 답
- 복잡도 : n (logn)^2


chapter 6

# dynamic programming
- 개념 : 중복되는 하위 문제를 기억했다가 재사용
- 응용 : 생물정보학, 제어이론, 정보이론, 운영연구, 인공지능, 컴파일러, 그래픽스 등.
- 대표 알고리즘:
    Unix diff
    Viterbi (HMM)
    Smith-Waterman (유전자 정렬)
    Bellman-Ford (최단 경로)
    CKY (문법 파싱)
- binary choice : weighted interval scheduling에서 time을 기준으로
    여기서부터의 최적의 선택은 이것이다.를 dp로 남겨놓을 수 있음



